{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1074: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1306: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1442: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:318: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:575: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=1,\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "from Model.net import BiSeNetV2\n",
    "from utils.Camvid_dataset import CamVidDataset\n",
    "\n",
    "from d2l import torch as d2l\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import monai\n",
    "from torchcontrib.optim import SWA\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = BiSeNetV2(num_classes=2)\n",
    " \n",
    "train_path = \"C:/Users/asus/Desktop/Video Substraction/DAVIS/ImageSets/480p/train.txt\"\n",
    "val_path   = \"C:/Users/asus/Desktop/Video Substraction/DAVIS/ImageSets/480p/trainval.txt\"\n",
    "root_path  = 'C:/Users/asus/Desktop/Video Substraction/DAVIS'\n",
    "\n",
    "\n",
    "train_dataset = CamVidDataset(train_path,root_path)\n",
    "val_dataset = CamVidDataset(val_path,root_path)\n",
    "\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True,drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True,drop_last=True)\n",
    "# training loop 100 epochs\n",
    "epochs_num = 100\n",
    "# 选用SGD优化器来训练\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "schedule = monai.optimizers.LinearLR(optimizer, end_lr=0.05, num_iter=int(epochs_num*0.75))\n",
    "# 使用SWA优化 来提升SGD的效果\n",
    "\n",
    "steps_per_epoch = int(len(train_loader.dataset) / train_loader.batch_size)\n",
    "swa_start = int(epochs_num*0.75)\n",
    "optimizer = SWA(optimizer, swa_start=swa_start*steps_per_epoch, swa_freq=steps_per_epoch, swa_lr=0.05)\n",
    " \n",
    "# 损失函数选用多分类交叉熵损失函数\n",
    "lossf = nn.CrossEntropyLoss(ignore_index=255)\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # No. of correct predictions, no. of predictions\n",
    "    metric = d2l.Accumulator(2)\n",
    " \n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # Required for BERT Fine-tuning (to be covered later)\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            output = net(X)\n",
    "            pred = output[0]\n",
    "            metric.add(d2l.accuracy(pred, y), d2l.size(y))\n",
    "    return metric[0] / metric[1]\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train_ch13(output_dir,net, train_iter, test_iter, loss, optimizer, num_epochs, schedule, swa_start=swa_start, devices=d2l.try_all_gpus()):\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1], legend=['train loss', 'train acc', 'test acc'])\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    # 用来保存一些训练参数\n",
    " \n",
    "    loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "    epochs_list = []\n",
    "    time_list = []\n",
    "    lr_list = []\n",
    "    \n",
    " \n",
    "    for epoch in range(num_epochs):\n",
    "        # Sum of training loss, sum of training accuracy, no. of examples,\n",
    "        # no. of predictions\n",
    "        metric = d2l.Accumulator(4)\n",
    "        for i, (X, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    " \n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(devices[0]) for x in X]\n",
    "            else:\n",
    "                X = X.to(devices[0])\n",
    "            gt = labels.long().to(devices[0])\n",
    " \n",
    "            net.train()\n",
    "            optimizer.zero_grad()\n",
    "            result = net(X)\n",
    "            pred = result[0]\n",
    "            seg_loss = loss(result[0], gt)\n",
    "\n",
    "            aux_loss_1 = loss(result[1], gt)\n",
    "            aux_loss_2 = loss(result[2], gt)\n",
    "            aux_loss_3 = loss(result[3], gt)\n",
    "            aux_loss_4 = loss(result[4], gt)\n",
    " \n",
    " \n",
    "            loss_sum = seg_loss + 0.2*aux_loss_1 + 0.2*aux_loss_2 + 0.2*aux_loss_3 + 0.2*aux_loss_4\n",
    "            l = loss_sum\n",
    "            loss_sum.sum().backward()\n",
    "            optimizer.step()\n",
    " \n",
    "            acc = d2l.accuracy(pred, gt)\n",
    "            metric.add(l, acc, labels.shape[0], labels.numel())\n",
    " \n",
    "            timer.stop()\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,(metric[0] / metric[2], metric[1] / metric[3], None))\n",
    "                \n",
    "        if optimizer.state_dict()['param_groups'][0]['lr']>0.05:\n",
    "            schedule.step()\n",
    " \n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        \n",
    "        if (epoch + 1) >= swa_start:\n",
    "            if epoch == 0 or epoch % 5 == 5 - 1 or epoch == num_epochs - 1:\n",
    "                # Batchnorm update\n",
    "                optimizer._reset_lr_to_swa()\n",
    "                optimizer.swap_swa_sgd()\n",
    "                optimizer.bn_update(train_iter, net, device='cuda')\n",
    "                test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "                optimizer.swap_swa_sgd()\n",
    "        \n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    " \n",
    "        print(f\"epoch {epoch+1}/{epochs_num} --- loss {metric[0] / metric[2]:.3f} --- train acc {metric[1] / metric[3]:.3f} --- test acc {test_acc:.3f} --- lr {optimizer.state_dict()['param_groups'][0]['lr']} --- cost time {timer.sum()}\")\n",
    "        \n",
    "        #---------保存训练数据---------------\n",
    "        df = pd.DataFrame()\n",
    "        loss_list.append(metric[0] / metric[2])\n",
    "        train_acc_list.append(metric[1] / metric[3])\n",
    "        test_acc_list.append(test_acc)\n",
    "        epochs_list.append(epoch+1)\n",
    "        time_list.append(timer.sum())\n",
    "        lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        \n",
    "        df['epoch'] = epochs_list\n",
    "        df['loss'] = loss_list\n",
    "        df['train_acc'] = train_acc_list\n",
    "        df['test_acc'] = test_acc_list\n",
    "        df[\"lr\"] = lr_list\n",
    "        df['time'] = time_list\n",
    "        \n",
    "        df.to_excel(output_dir + \"savefile/BiseNetv2_camvid.xlsx\")\n",
    "        #----------------保存模型------------------- \n",
    "        if np.mod(epoch+1, 5) == 0:\n",
    "            torch.save(net.state_dict(), output_dir+ f'checkpoints/BiseNetv2_{epoch+1}.pth')\n",
    " \n",
    "    # 保存下最后的model\n",
    "    torch.save(net.state_dict(), output_dir +  f'checkpoints/BiseNetv2_last.pth')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"C:/Users/asus/Desktop/Video Substraction/Output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ch13(output_dir,model, train_loader, val_loader, lossf, optimizer, epochs_num, schedule=schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_upsample() for <class 'torch.nn.modules.upsampling.Upsample'>.\n",
      "flops: 137051609088.0, params: 5099524.0\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "model = model.cuda()\n",
    "input = torch.randn(16, 3,448, 448).cuda() # (batch_size, num_channel, Height, Width)\n",
    "flops, params = profile(model, inputs=(input, )) \n",
    "print('flops: {}, params: {}'.format(flops, params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
